# Complete Enterprise SSO, RBAC, and Compliance Configuration
# Demonstrates the full power of Kolumn enterprise HCL resources

# =====================================
# ENTERPRISE IDENTITY MANAGEMENT
# =====================================

# Corporate SSO Provider with SCIM provisioning
create "kolumn_sso_provider" "corporate_okta" {
  name          = "Corporate Okta"
  provider_type = "okta"

  configuration {
    issuer_url    = "https://company.okta.com"
    client_id     = var.okta_client_id
    client_secret = var.okta_client_secret
    scopes        = ["openid", "profile", "email", "groups"]
    metadata_url  = "https://company.okta.com/.well-known/openid_configuration"
  }

  scim {
    enabled       = true
    endpoint_url  = "https://company.okta.com/api/v1/scim/v2"
    token         = var.okta_scim_token
    sync_groups   = true
    sync_users    = true
    sync_interval = "15m"
  }

  group_mapping = [
    {
      external_group = "DataEngineering"
      internal_role  = kolumn_role.data_engineer.name
    },
    {
      external_group = "CustomerService"
      internal_role  = kolumn_role.customer_service.name
    },
    {
      external_group = "DataStewards"
      internal_role  = kolumn_role.data_steward.name
    },
    {
      external_group = "ComplianceOfficers"
      internal_role  = kolumn_role.compliance_officer.name
    }
  ]

  provider_configurations = {
    postgres = {
      authentication_method = "jwt"
      jwt_validation        = true
      group_claim           = "groups"
    }
    kafka = {
      sasl_mechanism = "OAUTHBEARER"
      oauth_config = {
        token_endpoint = "https://company.okta.com/oauth2/v1/token"
        scope          = "kafka"
      }
    }
    dagster = {
      authentication_method = "oidc"
      group_claim           = "groups"
    }
  }
}

# =====================================
# DATA CLASSIFICATIONS & GOVERNANCE
# =====================================

# PII Classification with provider-specific encryption
create "kolumn_classification" "pii" {
  name        = "PII"
  description = "Personally Identifiable Information"

  requirements = {
    encryption      = true
    masking         = true
    audit_access    = true
    searchable      = true
    retention_years = 7
  }

  encryption_config = {
    postgres = {
      method         = "column_encryption"
      algorithm      = "AES-256-GCM"
      key_derivation = "database_native"
      deterministic  = true
      key_name       = "CEK_PII"
    }
    kafka = {
      method              = "field_level"
      algorithm           = "AES-256-CTR"
      at_rest             = true
      in_transit          = true
      envelope_encryption = true
    }
    s3 = {
      method            = "SSE-KMS"
      kms_key_alias     = "alias/pii-data-key"
      bucket_encryption = true
      object_tagging    = true
    }
  }
}

# Financial Classification
create "kolumn_classification" "financial" {
  name        = "FINANCIAL"
  description = "Financial data requiring enhanced security"

  requirements = {
    encryption      = true
    immutable       = true
    audit_changes   = true
    retention_years = 10
    tokenization    = true
  }

  encryption_config = {
    postgres = {
      method            = "tde"
      algorithm         = "AES-256-GCM"
      backup_encryption = true
    }
    kafka = {
      method          = "message_encryption"
      algorithm       = "AES-256-GCM"
      integrity_check = true
    }
  }
}

# Public Classification
create "kolumn_classification" "public" {
  name        = "PUBLIC"
  description = "Publicly accessible data"

  requirements = {
    encryption      = false
    retention_years = 3
  }

  encryption_config = {
    postgres = { method = "none" }
    kafka    = { method = "none" }
    s3       = { method = "SSE-S3" }
  }
}

# =====================================
# COMPLIANCE FRAMEWORKS
# =====================================

# GDPR Compliance Framework
create "kolumn_compliance_framework" "gdpr" {
  name      = "GDPR"
  framework = "EU General Data Protection Regulation"

  applies_to_classifications = [
    kolumn_classification.pii.name
  ]

  requirements = {
    right_to_erasure          = true
    data_portability          = true
    consent_tracking          = true
    breach_notification_hours = 72
    retention_max_years       = 7
    data_minimization         = true
  }

  controls = [
    {
      id             = "GDPR-7.1"
      name           = "Data Subject Rights"
      description    = "Implement data subject rights (access, rectification, erasure)"
      automated      = true
      test_frequency = "monthly"
    },
    {
      id             = "GDPR-32"
      name           = "Security of Processing"
      description    = "Ensure appropriate technical and organizational measures"
      automated      = true
      test_frequency = "weekly"
    }
  ]

  automated_testing {
    enabled             = true
    schedule            = "0 2 * * *" # Daily at 2 AM
    evidence_collection = true
    report_generation   = true
  }
}

# PCI-DSS Compliance Framework
create "kolumn_compliance_framework" "pci_dss" {
  name      = "PCI-DSS"
  framework = "Payment Card Industry Data Security Standard"

  applies_to_classifications = [
    kolumn_classification.financial.name
  ]

  requirements = {
    encryption_in_transit = true
    encryption_at_rest    = true
    key_rotation_days     = 90
    tokenization          = true
    secure_key_management = true
  }

  controls = [
    {
      id             = "PCI-3.4"
      name           = "Cardholder Data Encryption"
      description    = "Render cardholder data unreadable anywhere it is stored"
      automated      = true
      test_frequency = "daily"
    },
    {
      id             = "PCI-8.2"
      name           = "User Authentication"
      description    = "Assign unique ID to each person with computer access"
      automated      = true
      test_frequency = "weekly"
    }
  ]

  automated_testing {
    enabled             = true
    schedule            = "0 1 * * *"
    evidence_collection = true
    report_generation   = true
  }
}

# =====================================
# RBAC PERMISSIONS & ROLES
# =====================================

# Customer Service Permission with Masking
create "kolumn_permission" "read_customer_masked" {
  name = "read_customer_masked"
  actions = {
    select = true
    insert = false
    update = false
    delete = false
  }

  applies_to_classifications = [kolumn_classification.pii.name]

  transformations {
    required = true
    type     = "masking"
    provider_functions = {
      postgres = "mask_email(email), mask_phone(phone)"
      kafka    = "PII_MASKING_INTERCEPTOR"
    }
  }

  provider_configurations = {
    postgres = {
      operations    = ["SELECT"]
      schema_access = ["public", "analytics"]
    }
    kafka = {
      operations     = ["READ", "DESCRIBE"]
      topic_patterns = ["customer-*"]
    }
    dagster = {
      operations     = ["READ"]
      asset_patterns = ["customer_*"]
    }
  }

  audit_requirements {
    log_all_access        = true
    require_justification = false
    approval_workflow     = false
  }
}

# Data Engineer Full Access Permission
create "kolumn_permission" "data_engineer_access" {
  name = "data_engineer_access"
  actions = {
    select = true
    insert = true
    update = true
    delete = false # No delete for safety
  }

  applies_to_classifications = [
    kolumn_classification.pii.name,
    kolumn_classification.financial.name,
    kolumn_classification.public.name
  ]

  provider_configurations = {
    postgres = {
      operations    = ["SELECT", "INSERT", "UPDATE", "CREATE", "ALTER"]
      schema_access = ["public", "staging", "analytics"]
    }
    kafka = {
      operations     = ["READ", "WRITE", "CREATE", "DESCRIBE", "ALTER"]
      topic_patterns = ["*"]
    }
    dagster = {
      operations     = ["READ", "WRITE", "EXECUTE", "SCHEDULE"]
      asset_patterns = ["*"]
    }
  }

  audit_requirements {
    log_all_access        = true
    require_justification = true
    approval_workflow     = true
  }
}

# Compliance Officer Audit Permission
create "kolumn_permission" "compliance_audit" {
  name = "compliance_audit"
  actions = {
    select = true
    insert = false
    update = false
    delete = false
  }

  applies_to_classifications = [
    kolumn_classification.pii.name,
    kolumn_classification.financial.name,
    kolumn_classification.public.name
  ]

  provider_configurations = {
    postgres = {
      operations    = ["SELECT"]
      schema_access = ["audit", "compliance", "public"]
    }
    kafka = {
      operations     = ["READ", "DESCRIBE"]
      topic_patterns = ["audit-*", "compliance-*"]
    }
  }

  audit_requirements {
    log_all_access        = true
    require_justification = true
    approval_workflow     = false
  }
}

# =====================================
# ENTERPRISE ROLES
# =====================================

# Customer Service Role
create "kolumn_role" "customer_service" {
  name = "customer_service"
  permissions = [
    kolumn_permission.read_customer_masked.name
  ]

  capabilities {
    max_concurrent_queries = 5
    can_export_data        = false
    query_timeout_minutes  = 30
    emergency_access       = false
    dashboard_access       = true
  }

  provider_specific = {
    postgres = {
      row_level_security = true
      connection_limit   = 10
    }
    kafka = {
      consumer_group_prefix = "customer-service-"
      max_fetch_bytes       = "1MB"
    }
    dagster = {
      view_only            = true
      can_view_performance = false
    }
  }

  constraints = {
    time_based_access    = true
    business_hours_only  = true
    max_session_duration = "8h"
  }
}

# Data Engineer Role
create "kolumn_role" "data_engineer" {
  name = "data_engineer"
  permissions = [
    kolumn_permission.data_engineer_access.name
  ]

  capabilities {
    max_concurrent_queries = 20
    can_export_data        = true
    can_create_topics      = true
    can_modify_schemas     = true
    can_launch_jobs        = true
    can_batch_process      = true
    query_timeout_minutes  = 180
    emergency_access       = true
  }

  provider_specific = {
    postgres = {
      can_manage_indexes = true
      connection_limit   = 25
    }
    kafka = {
      can_alter_configs        = true
      can_manage_acls          = true
      can_create_schemas       = true
      max_partitions_per_topic = 100
    }
    dagster = {
      can_deploy_code      = true
      can_manage_schedules = true
      can_terminate_runs   = true
      can_backfill         = true
    }
  }
}

# Data Steward Role
create "kolumn_role" "data_steward" {
  name = "data_steward"
  permissions = [
    kolumn_permission.read_customer_masked.name,
    kolumn_permission.compliance_audit.name
  ]

  capabilities {
    max_concurrent_queries = 10
    can_export_data        = true
    can_create_alerts      = true
    can_manage_dashboards  = true
    query_timeout_minutes  = 60
  }

  provider_specific = {
    postgres = {
      can_view_performance = true
      can_kill_queries     = true
    }
    kafka = {
      can_view_all_consumer_groups = true
      can_reset_offsets            = true
      can_manage_quotas            = true
    }
    dagster = {
      can_view_performance = true
      dashboard_access     = true
    }
  }
}

# Compliance Officer Role
create "kolumn_role" "compliance_officer" {
  name = "compliance_officer"
  permissions = [
    kolumn_permission.compliance_audit.name
  ]

  capabilities {
    max_concurrent_queries = 15
    can_export_data        = true
    emergency_access       = true
    query_timeout_minutes  = 120
  }

  provider_specific = {
    postgres = {
      read_only            = true
      can_view_performance = true
    }
    kafka = {
      operations                   = ["READ", "DESCRIBE"]
      can_view_all_consumer_groups = true
    }
    dagster = {
      view_only            = true
      can_view_performance = true
    }
  }
}

# =====================================
# SERVICE ACCOUNTS
# =====================================

# Analytics Service Account
create "kolumn_service_account" "analytics_service" {
  name        = "analytics-service"
  description = "Service account for analytics processing"
  roles       = [kolumn_role.data_engineer.name]

  credentials = {
    postgres_user   = "analytics_service"
    kafka_client_id = "analytics-${var.environment}"
    dagster_user    = "analytics_service"
  }

  restrictions {
    ip_allowlist      = ["10.0.0.0/8", "172.16.0.0/12"]
    time_based_access = false
    mfa_required      = false
  }

  emergency_access {
    enabled                = true
    break_glass_procedures = true
    audit_all_actions      = true
  }
}

# Customer Service Application Account
create "kolumn_service_account" "customer_app" {
  name        = "customer-application"
  description = "Service account for customer service application"
  roles       = [kolumn_role.customer_service.name]

  credentials = {
    postgres_user   = "customer_app"
    kafka_client_id = "customer-app-${var.environment}"
  }

  restrictions {
    ip_allowlist      = ["10.0.100.0/24"]
    time_based_access = true
    mfa_required      = false
  }
}

# =====================================
# ENTERPRISE DISCOVERY & INTELLIGENCE
# =====================================

# AI-Powered Discovery Engine
create "kolumn_discovery_engine" "enterprise_discovery" {
  name = "Enterprise Data Discovery"

  discovery_types = ["schema", "pii", "lineage", "quality"]

  ai_configuration {
    enabled = true
    ml_models = {
      pii_detection        = "bert-base-pii-v2.1"
      pattern_matching     = "regex-enhanced-v1.0"
      confidence_threshold = 0.9
    }

    performance_optimization {
      parallel_processing = true
      batch_size          = 1000
      max_workers         = 8
    }
  }

  pii_detection {
    enabled              = true
    confidence_threshold = 0.85
    patterns = [
      "email", "phone", "ssn", "credit_card",
      "passport", "drivers_license", "ip_address"
    ]

    custom_patterns = {
      customer_id = "^CUST[0-9]{8}$"
      order_id    = "^ORD[0-9]{10}$"
    }

    auto_classification     = true
    manual_review_threshold = 0.7
  }

  lineage_tracking {
    enabled                 = true
    cross_provider          = true
    depth_limit             = 10
    include_transformations = true

    providers = [
      "postgres", "kafka", "dagster", "s3"
    ]
  }

  quality_monitoring {
    enabled = true
    metrics = ["completeness", "validity", "consistency", "accuracy"]
    alert_thresholds = {
      completeness = 0.95
      validity     = 0.98
      consistency  = 0.90
      accuracy     = 0.95
    }
  }

  scheduling {
    discovery_schedule = "0 2 * * 0" # Weekly on Sunday at 2 AM
    incremental_scan   = "0 6 * * *" # Daily at 6 AM
    lineage_refresh    = "0 4 * * *" # Daily at 4 AM
  }
}

# Data Lineage Tracking
create "kolumn_data_lineage" "enterprise_lineage" {
  name = "Enterprise Data Lineage"

  tracking_scope = {
    providers                  = ["postgres", "kafka", "dagster", "s3"]
    include_views              = true
    include_functions          = true
    include_materialized_views = true
  }

  lineage_rules = [
    {
      source_pattern      = "postgres:public.customers"
      target_pattern      = "kafka:customer-events"
      relationship        = "transforms_to"
      transformation_type = "cdc"
    },
    {
      source_pattern      = "kafka:customer-events"
      target_pattern      = "s3:customer-data-lake"
      relationship        = "archives_to"
      transformation_type = "batch_export"
    }
  ]

  performance_optimization {
    cache_lineage    = true
    cache_ttl        = "1h"
    async_processing = true
    batch_updates    = true
  }

  visualization {
    enabled          = true
    export_formats   = ["graphml", "json", "svg"]
    max_nodes        = 1000
    layout_algorithm = "hierarchical"
  }
}

# =====================================
# ENTERPRISE SECURITY & ENCRYPTION
# =====================================

# HSM Provider Configuration
create "kolumn_hsm_provider" "aws_cloudhsm" {
  name          = "AWS CloudHSM"
  provider_type = "aws_cloudhsm"

  configuration {
    cluster_id      = var.cloudhsm_cluster_id
    region          = var.aws_region
    crypto_user     = var.cloudhsm_crypto_user
    crypto_password = var.cloudhsm_crypto_password
  }

  key_management {
    auto_generate_keys    = true
    key_types             = ["AES-256", "RSA-2048", "ECC-P256"]
    key_rotation_schedule = "0 2 1 * *" # Monthly on 1st at 2 AM
  }

  performance_optimization {
    connection_pooling = true
    max_connections    = 10
    cache_keys         = true
    cache_ttl          = "4h"
  }

  compliance {
    fips_140_2_level_3 = true
    common_criteria    = true
    audit_logging      = true
  }
}

# Automated Key Rotation
create "kolumn_key_rotation" "automated_rotation" {
  name = "Automated Key Rotation"

  rotation_policy {
    frequency           = "monthly"
    schedule            = "0 3 1 * *" # 1st of month at 3 AM
    grace_period        = "7d"
    notification_window = "24h"
  }

  key_types = [
    {
      type               = "column_encryption"
      providers          = ["postgres", "mysql"]
      rotation_frequency = "quarterly"
    },
    {
      type               = "kafka_encryption"
      providers          = ["kafka"]
      rotation_frequency = "monthly"
    },
    {
      type               = "s3_kms"
      providers          = ["s3"]
      rotation_frequency = "annually"
    }
  ]

  backup_strategy {
    create_backup      = true
    backup_location    = "s3://company-key-backups/"
    encryption_at_rest = true
    retention_period   = "7y"
  }

  validation {
    test_new_keys          = true
    rollback_on_failure    = true
    health_checks          = true
    notification_endpoints = ["security-team@company.com"]
  }
}

# Enterprise Encryption Policy
create "kolumn_encryption_policy" "enterprise_encryption" {
  name = "Enterprise Encryption Policy"

  default_encryption {
    enabled        = true
    algorithm      = "AES-256-GCM"
    key_derivation = "database_native"
  }

  classification_policies = {
    pii = {
      encryption_required = true
      key_rotation_days   = 90
      algorithm           = "AES-256-GCM"
      backup_encryption   = true
    }
    financial = {
      encryption_required = true
      key_rotation_days   = 30
      algorithm           = "AES-256-GCM"
      hsm_required        = true
      backup_encryption   = true
    }
    public = {
      encryption_required = false
      algorithm           = "AES-128-GCM"
    }
  }

  provider_specific = {
    postgres = {
      column_encryption = true
      tde_enabled       = true
      backup_encryption = true
    }
    kafka = {
      encryption_in_transit      = true
      encryption_at_rest         = true
      schema_registry_encryption = true
    }
    s3 = {
      default_encryption       = "SSE-KMS"
      enforce_encryption       = true
      deny_unencrypted_uploads = true
    }
  }

  compliance_mapping = {
    gdpr    = ["encryption_at_rest", "encryption_in_transit"]
    pci_dss = ["hsm_for_financial", "key_rotation"]
    hipaa   = ["encryption_required", "access_logging"]
  }
}

# =====================================
# ENTERPRISE POLICY LIBRARY
# =====================================

# Built-in Policy Library
create "kolumn_policy_library" "enterprise_policies" {
  name = "Enterprise Security Policies"

  ddl_policies = [
    {
      name         = "prevent_production_drops"
      description  = "Prevent DROP operations in production"
      rule         = "DENY DROP TABLE, DROP DATABASE, DROP SCHEMA"
      environments = ["production"]
      exceptions   = ["scheduled_maintenance"]
    },
    {
      name                  = "require_backup_before_alter"
      description           = "Require backup before schema alterations"
      rule                  = "REQUIRE BACKUP BEFORE ALTER TABLE"
      environments          = ["production", "staging"]
      notification_required = true
    }
  ]

  data_access_policies = [
    {
      name           = "pii_access_logging"
      description    = "Log all access to PII data"
      rule           = "LOG ACCESS WHERE classification = 'PII'"
      applies_to     = ["postgres", "kafka"]
      retention_days = 2555 # 7 years
    },
    {
      name              = "financial_approval_required"
      description       = "Require approval for financial data access"
      rule              = "REQUIRE APPROVAL WHERE classification = 'FINANCIAL'"
      approval_workflow = true
      approvers         = ["data_steward", "compliance_officer"]
    }
  ]

  time_based_policies = [
    {
      name        = "business_hours_only"
      description = "Restrict sensitive data access to business hours"
      rule        = "ALLOW ACCESS BETWEEN 08:00 AND 18:00 WHERE classification IN ('PII', 'FINANCIAL')"
      timezone    = "America/New_York"
      exceptions  = ["emergency_access"]
    }
  ]

  compliance_policies = [
    {
      name        = "gdpr_data_retention"
      description = "Enforce GDPR data retention limits"
      rule        = "DELETE WHERE age > 7_years AND classification = 'PII'"
      framework   = "GDPR"
      automated   = true
    },
    {
      name        = "pci_tokenization"
      description = "Require tokenization for payment data"
      rule        = "TOKENIZE WHERE classification = 'FINANCIAL' AND type = 'payment_card'"
      framework   = "PCI-DSS"
      automated   = true
    }
  ]

  enforcement {
    real_time             = true
    policy_validation     = true
    impact_analysis       = true
    rollback_on_violation = true
  }
}

# =====================================
# ENTERPRISE AUDIT REPORTING
# =====================================

# Comprehensive Audit Reporter
create "kolumn_audit_reporter" "enterprise_audit" {
  name = "Enterprise Audit Reporter"

  frameworks = ["SOC2", "GDPR", "PCI-DSS", "HIPAA"]

  report_types = [
    {
      name       = "quarterly_compliance"
      frameworks = ["SOC2", "GDPR", "PCI-DSS"]
      schedule   = "0 9 1 1,4,7,10 *" # Quarterly
      format     = "pdf"
      recipients = ["compliance@company.com", "ciso@company.com"]
    },
    {
      name       = "monthly_access_review"
      frameworks = ["SOC2"]
      schedule   = "0 9 1 * *" # Monthly
      format     = "json"
      recipients = ["security-team@company.com"]
    },
    {
      name       = "daily_pii_access"
      frameworks = ["GDPR"]
      schedule   = "0 6 * * *" # Daily
      format     = "csv"
      recipients = ["data-protection@company.com"]
    }
  ]

  evidence_collection {
    automated          = true
    digital_signatures = true
    chain_of_custody   = true
    tamper_detection   = true

    storage {
      backend         = "s3"
      bucket          = "company-audit-evidence"
      encryption      = "SSE-KMS"
      retention_years = 7
    }
  }

  tamper_evident_storage {
    enabled                = true
    signing_algorithm      = "RSA-PSS"
    hash_algorithm         = "SHA-512"
    signature_verification = true

    immutable_storage {
      backend              = "s3_glacier"
      write_once_read_many = true
      legal_hold_support   = true
    }
  }

  performance_optimization {
    parallel_collection = true
    incremental_updates = true
    compression         = "gzip"
    batch_processing    = true
  }
}

# =====================================
# DATA OBJECTS WITH ENTERPRISE FEATURES
# =====================================

# Customer data object with comprehensive governance
create "kolumn_data_object" "customer" {
  name = "customer"

  column "id" {
    type        = "BIGINT"
    primary_key = true
    # No classification = no encryption for non-sensitive IDs
  }

  column "email" {
    type            = "VARCHAR(255)"
    unique          = true
    classifications = [kolumn_classification.pii.name]
    # Encryption and GDPR compliance auto-applied from PII classification
  }

  column "phone" {
    type            = "VARCHAR(20)"
    classifications = [kolumn_classification.pii.name]
  }

  column "first_name" {
    type            = "VARCHAR(100)"
    classifications = [kolumn_classification.pii.name]
  }

  column "last_name" {
    type            = "VARCHAR(100)"
    classifications = [kolumn_classification.pii.name]
  }

  column "total_spent" {
    type            = "DECIMAL(12,2)"
    classifications = [kolumn_classification.financial.name]
    # Financial encryption and PCI compliance auto-applied
  }

  column "status" {
    type            = "VARCHAR(20)"
    classifications = [kolumn_classification.public.name]
  }

  column "created_at" {
    type            = "TIMESTAMP"
    default         = "CURRENT_TIMESTAMP"
    classifications = [kolumn_classification.public.name]
  }

  # Provider-namespaced configurations
  config = {
    postgres = {
      schema             = "public"
      table_name         = "customers"
      email_check        = "email ~* '^[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\\\.[A-Za-z]{2,}$'"
      email_index_method = "btree"
    }
    kafka = {
      topic_name         = "customer-events"
      partitions         = 6
      replication_factor = 3
      retention_ms       = 604800000 # 7 days
      compression_type   = "lz4"
    }
    s3 = {
      bucket_name   = "customer-data-lake"
      storage_class = "STANDARD_IA"
      encryption    = "AES256"
      versioning    = true
    }
  }

  # Governance automatically derived from column classifications:
  # - GDPR compliance applied to PII columns
  # - PCI compliance applied to financial columns
  # - Public data gets minimal governance
}

# =====================================
# OPERATIONAL COMMANDS (Not HCL)
# =====================================

# Note: These remain as CLI commands for operational tasks:
#
# kolumn security ddl validate --impact-analysis customer_migration.sql
# kolumn security emergency enable --justification "Production incident #123" --duration 2h
# kolumn security scrub-secrets --ephemeral-mode --verify
#
# kolumn compliance validate --framework gdpr --generate-report
# kolumn compliance evidence collect --period quarterly --digital-signature
# kolumn compliance gap-analysis --baseline soc2-2017 --target soc2-2023
#
# kolumn scan pii --ai-powered --confidence-threshold 0.9
# kolumn scan lineage --cross-provider --export graphml
# kolumn scan performance --alert-degradation --benchmark-mode